{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Algorithm - Exe3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION WITH PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business problem description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information was collected by Ronny from the 1994 Census bureau database. Using the following criteria, a set of relatively clean records was extracted: ((AAGE>16) && (AGI>100) && (AFNLWGT>1) && (HRSWK>0)). The task of prediction is to decide if a person makes over $50K a year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset contains the following features:\n",
    "#### 1) Age : Age of the person\n",
    "#### 2) Workclass : Working/labour class of the person\n",
    "#### 3) fnlwgt : The weights on the files of the Current Population Survey (CPS) are managed by independent estimates of the US civilian noninstitutional society.\n",
    "#### 4) Education : Education of the person\n",
    "#### 5) education.num = number of education of the person\n",
    "#### 6) marital.status = marital status  of the person\n",
    "#### 7) occupation = occupation of the person\n",
    "#### 8) relationship = relationship status of the person\n",
    "#### 9) race =  race of the person \n",
    "#### 10) sex = sex of the person\n",
    "#### 11) capital.gain = profit of a person in stocks and other assets\n",
    "#### 12) capital.loss = loss of a person in stocks and other assets\n",
    "#### 13) hours.per.week = how many hours a week, the person works?\n",
    "#### 14) native.country = what is the native place of the person\n",
    "#### 15) income = income of that person\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Income is the dependent variable as we need to predict if the person makes over 50,000 dollars in a year.\n",
    "Other than that, all the other thirteen features are independent features\n",
    "Our task is to predict whether a person makes over or less than 50,000 dollars in a year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We start by importing the dataset and acquiring basic info about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\Shrita\\\\Downloads\\\\exe3\\\\adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We are dealing with 6 integer columns and the other columns have categorical data which needs to encoded in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The dataset has 32561 rows and 15 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "msno.bar(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "according to this, the dataset has no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, '?' indicates missing values. There are almost 1000 rows with '?'. It wont be right to remove them so we will replace them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df == '?'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "msno.bar(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can clearly see the missing values. We will replace them with mode of the respective column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['workclass'].fillna(df['workclass'].mode()[0], inplace=True)\n",
    "df['occupation'].fillna(df['occupation'].mode()[0], inplace=True)\n",
    "df['native.country'].fillna(df['native.country'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking null values again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "msno.bar(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### And we are all clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = ['Over $50k','Below $50k']\n",
    "sizes = [df['income'].value_counts()[0],\n",
    "         df['income'].value_counts()[1]]\n",
    "\n",
    "\n",
    "# print(sizes) # adds up to 1433, which is the total number of participants\n",
    "\n",
    "fig1 = plt.figure(figsize=(20,9))\n",
    "\n",
    "ax1=fig1.add_subplot(121)\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True, colors = ['#003f5c', '#bc5090'])\n",
    "ax1.set_title('Income Count of the Dataset',fontsize = 20)\n",
    "ax1.axis('equal')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all the rows that are being examined, a little over 75% of the total population having the income more than 50,000 dollars per year. And the population having the income lower than 50,000 dollars is 24%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = ['Prof-specialty','Craft-repair','Exec-managerial','Adm-clerical','Sales','Other-service','Machine-op-inspct','Transport-moving','Handlers-cleaners','Farming-fishing','Tech-support','Protective-serv','Priv-house-serv','Armed-Forces']\n",
    "sizes = [df['occupation'].value_counts()[0],\n",
    "         df['occupation'].value_counts()[1],\n",
    "         df['occupation'].value_counts()[2],\n",
    "         df['occupation'].value_counts()[3],\n",
    "         df['occupation'].value_counts()[4],\n",
    "         df['occupation'].value_counts()[5],\n",
    "         df['occupation'].value_counts()[6],\n",
    "         df['occupation'].value_counts()[7],\n",
    "         df['occupation'].value_counts()[8],\n",
    "         df['occupation'].value_counts()[9],\n",
    "         df['occupation'].value_counts()[10],\n",
    "         df['occupation'].value_counts()[11],\n",
    "         df['occupation'].value_counts()[12],\n",
    "         df['occupation'].value_counts()[13]\n",
    "        \n",
    "        ]\n",
    "\n",
    "\n",
    "# print(sizes) # adds up to 1433, which is the total number of participants\n",
    "\n",
    "fig1 = plt.figure(figsize=(20,12))\n",
    "\n",
    "ax1=fig1.add_subplot(121)\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True, colors = ['y','#bc5090','khaki','tan','g'])\n",
    "ax1.set_title('Occupation Count of the dataset',fontsize=20)\n",
    "ax1.axis('equal')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The occupation that are very common in the dataset are Professional-speciality, Craft repair and Executive managerial postions. And the least common occupations are Armed forces and Private house servant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital.gain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f= plt.figure(figsize=(15,7))\n",
    "\n",
    "ax1=f.add_subplot()\n",
    "\n",
    "sns.kdeplot(df.loc[df['income'] == '<=50K', 'education.num'], label='<=50K', shade = True)\n",
    "sns.kdeplot(df.loc[df['income'] == '>50K', 'education.num'], label='>=50K', shade = True)\n",
    "\n",
    "ax1.set_title('Does studying for more years lead to higher income?',fontsize = 20)\n",
    "ax1.legend(loc = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an interesting observation to be noted in this graph. People who had the income lower than 50,000 dollars had an education of 9-10 years. While People who had a salary of more than 50,000 dollars in a year had studied for 12-14.5 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(15,7))\n",
    "\n",
    "ax1=f.add_subplot()\n",
    "sns.kdeplot(df.loc[df['income'] == '<=50K', 'age'], label='<=50K', shade = True)\n",
    "sns.kdeplot(df.loc[df['income'] == '>50K', 'age'], label='>=50K', shade = True)\n",
    "plt.title('Do older people earn more?', fontsize = 18)\n",
    "ax1.legend(loc = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph also reveals an exciting observation. 20-28 year old people had salary of less than 50,000 dollars per year. And people who are aged above 30 till 50 had a higher salary(greater than 50,000 dollars a year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(15,7))\n",
    "\n",
    "ax1=f.add_subplot()\n",
    "sns.kdeplot(df.loc[df['sex'] == 'Male', 'hours.per.week'], label='Male')\n",
    "sns.kdeplot(df.loc[df['sex'] == 'Female', 'hours.per.week'], label='Female')\n",
    "ax1.set_title('Do men work more than women?',fontsize = 20)\n",
    "ax1.legend(loc = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows a normal distribution. That means working for 30-50 hours is very common whereas, working for less than 20 hours and working for more than 60 hours is very uncommon.\n",
    "Males work slightly more than women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(40,9))\n",
    "\n",
    "ax1=f.add_subplot(121)\n",
    "sns.countplot(df['race'], hue = df['income'])\n",
    "plt.title('Racial differences in Income', fontsize = 18)\n",
    "ax1.legend(loc = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset shows that the income is higher for white and Asian-Pac-Islander compared to other races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(30,9))\n",
    "\n",
    "ax1=f.add_subplot(121)\n",
    "sns.scatterplot(data=df, x=\"capital.gain\", y=\"hours.per.week\", s=100, color=\".2\", marker=\"+\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People who work 20-60 hours per week have capital gain of 40k and very rarely they also have capital gain of more than 90. But people who work for less than 20 hours and more than 80 hours has slightly lower gain in capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(40,9))\n",
    "\n",
    "ax1=f.add_subplot(121)\n",
    "sns.countplot(df['workclass'], hue = df['income'])\n",
    "plt.title('Which workclass will have higher income?', fontsize = 18)\n",
    "ax1.legend(loc = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Private and self-employed workclass has higher salary compared to other workclasses. Whereas, people who have never worked or are working without salaray have very low income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(40,9))\n",
    "\n",
    "ax1=f.add_subplot(121)\n",
    "sns.countplot(df['race'], hue = df['occupation'])\n",
    "plt.title('Which occupation is more common in respective races', fontsize = 18)\n",
    "ax1.legend(loc = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very common to work in a Professional speciality in white and asian people. Whereas, black people had maximum jobs in the 'other occupations' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(45,9))\n",
    "\n",
    "ax1=f.add_subplot(121)\n",
    "sns.countplot(df['occupation'], hue = df['income'])\n",
    "plt.title('Which occupation has higher income?', fontsize = 18)\n",
    "ax1.legend(loc = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Professional speciality and admistrative clearical jobs had higher than 50k dollars per year of income. We can see that in the sales, cleaners and craft category, people have much lower salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(29,7))\n",
    "\n",
    "ax1=f.add_subplot(121)\n",
    "sns.barplot(x = 'workclass', y = 'age', data = df)\n",
    "ax1.set(xlabel='workclass', ylabel='age')\n",
    "ax1.set_title('Workclass vs Age',fontsize = 20)\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x() + p.get_width()/2, height + 0.005, '{:1.4f}'.format(height), ha=\"center\") \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class without pay has maximum people aged between 45-50. And most of the people who have never worked are aged below 20. Alos, people who are self-employed are aged between 38-41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, all the workclasses like Local and state gov had ages 20-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(30,6))\n",
    "\n",
    "ax1=f.add_subplot(121)\n",
    "sns.countplot(df['sex'], hue = df['income'])\n",
    "plt.title('Are Men paid more than Women?', fontsize = 18)\n",
    "ax1.legend(loc = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Men on average have higher salary than Women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(30,15))\n",
    "\n",
    "ax1=f.add_subplot(221)\n",
    "sns.countplot(x='marital.status', hue=\"income\", data=df , palette = 'twilight_shifted')\n",
    "plt.title('Do seperated people have higher income?', fontsize = 18)\n",
    "ax1.legend(loc = 1)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that married people had higher income. But the people who were married have lower salary this might be because most people who are under 20 years of age are unmarried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income_int'] = df['income'].map({'<=50K' : 0, '>=50K' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(40,6))\n",
    "\n",
    "ax=f.add_subplot(121)\n",
    "sns.stripplot(data=df,\n",
    "         x='education',\n",
    "         y='workclass',\n",
    "         jitter=True)\n",
    "ax.set_title('Does education affect working class?')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the graph that people who have never worked or have jobs that are unpaid have lower quality of education. But they other work classes had masters and doctorate degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.lmplot(data=df,\n",
    "           x=\"hours.per.week\",\n",
    "           y=\"age\", height = 7)\n",
    "plt.title('Do younger people work more?', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People that are older than 20 and younger than 70 work for 30-70 hours per week. On the other hand, Older people had very low working hours in a week. Which means that younger people had more working hours than older people(70-90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Classifiers and datasets (Training and Test)\n",
    "### I will break down the process into 3 parts and check respective accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------PART-1-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the column 'income_int' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['income_int'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the dataset into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['income'], axis=1)\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As most of the columns have categorical variables we will convert them into integer values first\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also convert the income column seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "categorical = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']\n",
    "for feature in categorical:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        X[feature] = le.fit_transform(X[feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the columns have different scales in X set, we will bring them down to one scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X  = pd.DataFrame(scaler.fit_transform(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test set split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the X and y sets into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I want to check the accuracy first without adjusting parametrs and without applying PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying logistic regression on the training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Logistic regression on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with all the features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The inital accuracy of the model is 82.17%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA has selected 14 components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the 14 components that were selected explain more than 97 percent of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlim(0,14,1)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 Components explain 90 and more percent of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data=np.c_[X, y], columns=['Feature 1', 'Feature 2', 'Feature 3','Feature 4','Feature 5','Feature 6','Feature 7', 'Feature 8', 'Feature 9','Feature 10','Feature 11','Feature12','Feature13','Feature14','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df1['label'] = le.fit_transform(df1['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df1.drop(['label'], axis=1)\n",
    "y1 = df1['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(X1, y1, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with all the features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the components selected by PCA, I got 82% of acuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens when I choose only 11 components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, I will check with only 11 components. Removing the last three columns in X set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['income','native.country', 'hours.per.week', 'capital.loss'], axis=1)\n",
    "y = df['income']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "categorical = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex']\n",
    "for feature in categorical:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        X_train[feature] = le.fit_transform(X_train[feature])\n",
    "        X_test[feature] = le.transform(X_test[feature])\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n",
    "\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X.columns)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with the first 11 features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, I will check with only 12 components. Removing the last two columns in X set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['income','native.country', 'hours.per.week'], axis=1)\n",
    "y = df['income']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "categorical = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex']\n",
    "for feature in categorical:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        X_train[feature] = le.fit_transform(X_train[feature])\n",
    "        X_test[feature] = le.transform(X_test[feature])\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n",
    "\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X.columns)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with the first 11 features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['income'], axis=1)\n",
    "y = df['income']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "categorical = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']\n",
    "for feature in categorical:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        X_train[feature] = le.fit_transform(X_train[feature])\n",
    "        X_test[feature] = le.transform(X_test[feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n",
    "\n",
    "\n",
    "pca= PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "dim = np.argmax(cumsum >= 0.90) + 1\n",
    "print('The number of dimensions required to preserve 90% of variance is',dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we blindly trust that all the features are correlated to the dependent variable, we get lower accuracy\n",
    "### PCA helps to not only reduce the dimension, but also selecting the perfect features. The maximum component suggested by PCA was 12. When I tried adding only 12 components to the dataset , I saw a higher accuracy. This was because a total of 7% of variance was explained by the dropped columns. \n",
    "### The following code computes PCA without reducing dimensionality, then computes the minimum number of dimensions required to preserve 90% of the training set variance.\n",
    "### However, If we go lower than 12 component, the dimensions do not  explain 90% of the variance. That is why the accuracy for 11 components was much lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we need higher accuracy in the model and as suggested by PCA algorithm, I select 12 components in the model and get the final accuracy of 82.27%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
